
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Learn AI, ML, and Deep Learning in the simplest way possible">
      
      
        <meta name="author" content="Your Learning Journey">
      
      
      
        <link rel="prev" href="../lesson5/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Lesson 6 - Under the Hood - SimplestLearn Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.css">
    
      <link rel="stylesheet" href="../../assets/css/mermaid-custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lesson-6-under-the-hood-building-a-decision-tree-by-hand" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="SimplestLearn Wiki" class="md-header__button md-logo" aria-label="SimplestLearn Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SimplestLearn Wiki
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Lesson 6 - Under the Hood
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/trinhdoduyhungss/simplestlearn.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    simplestlearn.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="SimplestLearn Wiki" class="md-nav__button md-logo" aria-label="SimplestLearn Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    SimplestLearn Wiki
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/trinhdoduyhungss/simplestlearn.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    simplestlearn.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Lessons
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lessons
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lesson1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 1 - Introduction to AI/ML/DL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lesson2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 2 - Three Flavors of ML
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lesson3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 3 - Classification vs Regression
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lesson4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 4 - Getting Your Data Ready
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lesson5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 5 - Your First AI Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Lesson 6 - Under the Hood
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Lesson 6 - Under the Hood
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#part-1-from-flowchart-to-code" class="md-nav__link">
    <span class="md-ellipsis">
      Part 1: From Flowchart to Code
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-2-the-rules-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      Part 2: The "Rules" in Python
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-3-putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      Part 3: Putting It All Together
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-4-the-aha-moment-why-we-use-toolboxes" class="md-nav__link">
    <span class="md-ellipsis">
      Part 4: The "Aha!" Moment - Why We Use Toolboxes
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-5-building-a-real-learning-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Part 5: Building a Real Learning Algorithm
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 5: Building a Real Learning Algorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tool-1-recursion-the-endless-mirror" class="md-nav__link">
    <span class="md-ellipsis">
      Tool 1: Recursion (The Endless Mirror)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-2-data-structures-the-trees-blueprint" class="md-nav__link">
    <span class="md-ellipsis">
      Tool 2: Data Structures (The Tree's Blueprint)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-3-gini-impurity-the-purity-score" class="md-nav__link">
    <span class="md-ellipsis">
      Tool 3: Gini Impurity (The "Purity" Score)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-code-step-by-step-a-visual-walkthrough" class="md-nav__link">
    <span class="md-ellipsis">
      The Code, Step-by-Step: A Visual Walkthrough
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-full-code-a-real-decision-tree" class="md-nav__link">
    <span class="md-ellipsis">
      The Full Code: A Real Decision Tree
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-6-lets-discuss" class="md-nav__link">
    <span class="md-ellipsis">
      Part 6: Let's Discuss!
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="lesson-6-under-the-hood-building-a-decision-tree-by-hand">Lesson 6: Under the Hood - Building a Decision Tree by Hand! üõ†Ô∏è<a class="headerlink" href="#lesson-6-under-the-hood-building-a-decision-tree-by-hand" title="Permanent link">&para;</a></h1>
<p>Welcome back, AI builder!</p>
<p>In our last lesson, we used the power of <code>scikit-learn</code> to build a Decision Tree model in just a few lines of code. It felt a bit like magic, right? You call <code>.fit()</code> and suddenly the computer has "learned."</p>
<p>Today, we're going to become the magicians. We're going to pull back the curtain and see what's happening inside that <code>.fit()</code> method. We'll build our very own Decision Tree from scratch using nothing but basic Python.</p>
<hr />
<h3 id="part-1-from-flowchart-to-code">Part 1: From Flowchart to Code<a class="headerlink" href="#part-1-from-flowchart-to-code" title="Permanent link">&para;</a></h3>
<p>Let's look at our Decision Tree flowchart from the last lesson one more time.</p>
<pre class="mermaid"><code>graph TD
    A{Likes Video Games?} --&gt;|"Yes (1)"| B{Likes Superheroes?};
    A --&gt;|"No (0)"| C{Likes Superheroes?};
    B --&gt;|"Yes (1)"| D["Predict: Likes Pizza! (1)"];
    B --&gt;|"No (0)"| E["Predict: Likes Pizza! (1)"];
    C --&gt;|"Yes (1)"| F["Predict: Likes Pizza! (1)"];
    C --&gt;|"No (0)"| G["Predict: Does NOT Like Pizza! (0)"];</code></pre>
<p>This flowchart is just a set of rules. We can read it like a story: "First, ask if the student likes video games. If the answer is yes, then ask if they like superheroes..." and so on.</p>
<p>We can translate this <em>exact</em> story into Python using <code>if/else</code> statements.</p>
<hr />
<h3 id="part-2-the-rules-in-python">Part 2: The "Rules" in Python<a class="headerlink" href="#part-2-the-rules-in-python" title="Permanent link">&para;</a></h3>
<p>Let's create our own prediction function called <code>predict_pizza_by_hand</code>. This function will take a student's data as a list (e.g., <code>[1, 0]</code>) and follow our rules.</p>
<p>The first element in the list (<code>student[0]</code>) will be "Likes Video Games?", and the second element (<code>student[1]</code>) will be "Likes Superheroes?".</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">predict_pizza_by_hand</span><span class="p">(</span><span class="n">student</span><span class="p">):</span>
    <span class="c1"># The first question in our flowchart</span>
    <span class="k">if</span> <span class="n">student</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Do they like video games?</span>
        <span class="c1"># If YES, we go down the left side of the tree.</span>
        <span class="c1"># Now we ask the second question.</span>
        <span class="k">if</span> <span class="n">student</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Do they also like superheroes?</span>
            <span class="k">return</span> <span class="s2">&quot;Likes Pizza!&quot;</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># They don&#39;t like superheroes.</span>
            <span class="k">return</span> <span class="s2">&quot;Likes Pizza!&quot;</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># They do NOT like video games.</span>
        <span class="c1"># If NO, we go down the right side of the tree.</span>
        <span class="c1"># Now we ask the second question.</span>
        <span class="k">if</span> <span class="n">student</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Do they like superheroes?</span>
            <span class="k">return</span> <span class="s2">&quot;Likes Pizza!&quot;</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># They don&#39;t like superheroes either.</span>
            <span class="k">return</span> <span class="s2">&quot;Does NOT Like Pizza!&quot;</span>
</code></pre></div>
<p>Look at that! The <code>if/else</code> statements are a perfect mirror of the branches in our flowchart. We've just manually coded the "brain" of our Decision Tree.</p>
<hr />
<h3 id="part-3-putting-it-all-together">Part 3: Putting It All Together<a class="headerlink" href="#part-3-putting-it-all-together" title="Permanent link">&para;</a></h3>
<p>Now let's use our hand-built model to make a prediction, just like we did in the last lesson.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># This is our hand-built model!</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict_pizza_by_hand</span><span class="p">(</span><span class="n">student</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">student</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">student</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Likes Pizza!&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Likes Pizza!&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">student</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Likes Pizza!&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Does NOT Like Pizza!&quot;</span>

<span class="c1"># Let&#39;s test it on Frank, who likes games (1) but not heroes (0)</span>
<span class="n">frank</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">predict_pizza_by_hand</span><span class="p">(</span><span class="n">frank</span><span class="p">)</span>

<span class="c1"># See the result!</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Our hand-built model predicts Frank:&quot;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>

<span class="c1"># Let&#39;s test it on David, who doesn&#39;t like games (0) or heroes (0)</span>
<span class="n">david</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">predict_pizza_by_hand</span><span class="p">(</span><span class="n">david</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Our hand-built model predicts David:&quot;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>

<span class="c1"># The output will be:</span>
<span class="c1"># Our hand-built model predicts Frank: Likes Pizza!</span>
<span class="c1"># Our hand-built model predicts David: Does NOT Like Pizza!</span>
</code></pre></div>
<p>It works perfectly! We have successfully created a machine learning model from scratch that can make predictions based on our specific rules.</p>
<hr />
<h3 id="part-4-the-aha-moment-why-we-use-toolboxes">Part 4: The "Aha!" Moment - Why We Use Toolboxes<a class="headerlink" href="#part-4-the-aha-moment-why-we-use-toolboxes" title="Permanent link">&para;</a></h3>
<p>This is great, but you might be thinking: "If we can do this by hand, why do we need <code>scikit-learn</code>?"</p>
<p>That's the most important question!</p>
<p>Our hand-built model is <strong>not learning</strong>. We looked at the data and <em>we</em> decided what the rules should be. We hard-coded the <code>if/else</code> statements ourselves. If we got new data, our model wouldn't change.</p>
<p>The magic of <code>scikit-learn</code>'s <code>.fit()</code> method is that it does all of this for us! It looks at the data and <strong>automatically discovers the best <code>if/else</code> rules to use</strong>. It figures out the best questions to ask and in what order to make the most accurate predictions.</p>
<p>If our data had 100 features, we would go crazy trying to write all the <code>if/else</code> statements by hand. But <code>.fit()</code> can figure it out in a fraction of a second.</p>
<p>So, by building a model by hand, you've learned the secret of what a Decision Tree really is: it's just a smart set of <code>if/else</code> rules. And now you can truly appreciate why toolboxes like <code>scikit-learn</code> are so powerful‚Äîthey are masters at finding those rules for us.</p>
<hr />
<h3 id="part-5-building-a-real-learning-algorithm">Part 5: Building a <em>Real</em> Learning Algorithm<a class="headerlink" href="#part-5-building-a-real-learning-algorithm" title="Permanent link">&para;</a></h3>
<p><strong>The Challenge:</strong> Welcome to the deep end of the pool! The rest of this lesson is a challenge. It's a peek into how a <em>real</em> learning algorithm works. It uses some more advanced ideas, but if you take it slow, you'll be able to see the real magic behind machine learning. Don't worry if you don't get it all on the first try‚Äîthe goal is to see how it's done!</p>
<h4 id="tool-1-recursion-the-endless-mirror"><strong>Tool 1: Recursion (The Endless Mirror)</strong><a class="headerlink" href="#tool-1-recursion-the-endless-mirror" title="Permanent link">&para;</a></h4>
<p>Imagine you're standing between two mirrors. You see a reflection of a reflection of a reflection... forever! That's <strong>recursion</strong>. In programming, it's a function that calls <em>itself</em> to solve a smaller piece of the same problem. We'll use this to "grow" our tree, with each branch being a smaller version of the tree.</p>
<h4 id="tool-2-data-structures-the-trees-blueprint"><strong>Tool 2: Data Structures (The Tree's Blueprint)</strong><a class="headerlink" href="#tool-2-data-structures-the-trees-blueprint" title="Permanent link">&para;</a></h4>
<p>How do we store a tree in code? We can use a <strong>dictionary</strong> or a <strong>class</strong>! Each "node" (or question) in our tree can hold the question and its "left" and "right" branches, which are more nodes.</p>
<h4 id="tool-3-gini-impurity-the-purity-score"><strong>Tool 3: Gini Impurity (The "Purity" Score)</strong><a class="headerlink" href="#tool-3-gini-impurity-the-purity-score" title="Permanent link">&para;</a></h4>
<p>This is the secret sauce. How does the algorithm know which question is best? It uses a "purity score" to check how well a question splits the data.</p>
<ul>
<li>
<p>A <strong>perfectly pure</strong> group has a score of <strong>0</strong> (e.g., a group of students who all like pizza).</p>
</li>
<li>
<p>A <strong>totally mixed</strong> group has a score of <strong>0.5</strong> (e.g., a group with 50% pizza lovers and 50% pizza haters).</p>
</li>
</ul>
<p>The algorithm calculates the purity score for every possible question and picks the one that creates the purest groups.</p>
<h4 id="the-code-step-by-step-a-visual-walkthrough"><strong>The Code, Step-by-Step: A Visual Walkthrough</strong><a class="headerlink" href="#the-code-step-by-step-a-visual-walkthrough" title="Permanent link">&para;</a></h4>
<p>Let's trace the computer's "thinking" as it starts to build the tree.</p>
<p><strong>Input:</strong> Our full dataset of 4 students.
<div class="highlight"><pre><span></span><code>[[1, 1, 1],
 [0, 1, 1],
 [1, 0, 1],
 [0, 0, 0]]
</code></pre></div>
The computer's first goal is to find the single best question to ask to split this group.</p>
<p><strong>Step 1: Calculate the Starting Purity</strong>
First, the computer looks at the whole group. There are 3 pizza lovers (1) and 1 hater (0). This is a pretty mixed group.</p>
<ul>
<li>
<p><strong>Computation:</strong> The Gini Impurity is <code>1 - ((3/4)^2 + (1/4)^2) = 1 - (0.5625 + 0.0625) = 0.375</code>.</p>
</li>
<li>
<p><strong>Output:</strong> The starting "impurity" is 0.375. The goal is to ask a question that lowers this number as much as possible.</p>
</li>
</ul>
<pre class="mermaid"><code>graph TD
    subgraph Starting Group
        A["[1,1,1], [0,1,1], [1,0,1], [0,0,0]"]
    end
    B["Gini = 0.375"]
    A --&gt; B</code></pre>
<p><strong>Step 2: Test the First Question ("Likes Video Games?")</strong>
The computer pretends to split the group based on this question.</p>
<pre class="mermaid"><code>graph TD
    subgraph "Split on 'Likes Video Games?'"
        A["Parent Gini = 0.375"] --&gt; B{Likes Games?};
        B --&gt;|Yes| C["Left Group: [1,1,1], [1,0,1]&lt;br&gt;2 Likes Pizza, 0 Hates&lt;br&gt;&lt;b&gt;Gini = 0.0 (Perfectly Pure!)&lt;/b&gt;"];
        B --&gt;|No| D["Right Group: [0,1,1], [0,0,0]&lt;br&gt;1 Likes Pizza, 1 Hates&lt;br&gt;&lt;b&gt;Gini = 0.5 (Totally Mixed!)&lt;/b&gt;"];
    end</code></pre>
<ul>
<li>
<p><strong>Computation:</strong> The computer calculates a weighted average of the new impurity: <code>(2/4)*0.0 + (2/4)*0.5 = 0.25</code>. The "Information Gain" (how much the impurity went down) is <code>0.375 - 0.25 = 0.125</code>.</p>
</li>
<li>
<p><strong>Output:</strong> The score for this question is <strong>0.125</strong>.</p>
</li>
</ul>
<p><strong>Step 3: Test the Second Question ("Likes Superheroes?")</strong>
Now the computer "forgets" the last split and tries again with the next question.</p>
<pre class="mermaid"><code>graph TD
    subgraph "Split on 'Likes Superheroes?'"
        A["Parent Gini = 0.375"] --&gt; B{Likes Heroes?};
        B --&gt;|Yes| C["Left Group: [1,1,1], [0,1,1]&lt;br&gt;2 Likes Pizza, 0 Hates&lt;br&gt;&lt;b&gt;Gini = 0.0 (Perfectly Pure!)&lt;/b&gt;"];
        B --&gt;|No| D["Right Group: [1,0,1], [0,0,0]&lt;br&gt;1 Likes Pizza, 1 Hates&lt;br&gt;&lt;b&gt;Gini = 0.5 (Totally Mixed!)&lt;/b&gt;"];
    end</code></pre>
<ul>
<li>
<p><strong>Computation:</strong> The weighted average is the same: <code>(2/4)*0.0 + (2/4)*0.5 = 0.25</code>. The "Information Gain" is also <code>0.375 - 0.25 = 0.125</code>.</p>
</li>
<li>
<p><strong>Output:</strong> The score for this question is <strong>0.125</strong>.</p>
</li>
</ul>
<p><strong>Step 4: The Decision</strong>
The computer compares the scores. In this case, they're tied! In a tie, the computer just picks the first one it tried.</p>
<ul>
<li><strong>The Winner:</strong> The best first question is "Likes Video Games?".</li>
</ul>
<p><strong>Step 5: The Recursion</strong>
The computer now has the root of its tree! It then repeats this <em>entire process</em> on the smaller groups.</p>
<ol>
<li>
<p>It runs the <code>get_best_split</code> logic on the "Yes" group.</p>
</li>
<li>
<p>It runs the <code>get_best_split</code> logic on the "No" group.</p>
</li>
</ol>
<p>This is the "endless mirror" of recursion in action! It continues until the groups are pure.</p>
<p>This whole process of testing splits and finding the one that lowers the impurity score the most is the "magic" inside the <code>.fit()</code> method!</p>
<h4 id="the-full-code-a-real-decision-tree"><strong>The Full Code: A Real Decision Tree</strong><a class="headerlink" href="#the-full-code-a-real-decision-tree" title="Permanent link">&para;</a></h4>
<p>This code puts all those ideas together. It's complex, but now you can see the "thinking" that happens inside it.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># A class to represent a single node in our decision tree</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Node</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">info_gain</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_index</span> <span class="o">=</span> <span class="n">feature_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">left</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">right</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">info_gain</span> <span class="o">=</span> <span class="n">info_gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>

<span class="c1"># The main Decision Tree class</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MyDecisionTree</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span> <span class="o">=</span> <span class="n">min_samples_split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">build_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">curr_depth</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dataset</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span> <span class="ow">and</span> <span class="n">curr_depth</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">:</span>
            <span class="n">best_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_best_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;info_gain&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">left_subtree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_tree</span><span class="p">(</span><span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;dataset_left&quot;</span><span class="p">],</span> <span class="n">curr_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">right_subtree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_tree</span><span class="p">(</span><span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;dataset_right&quot;</span><span class="p">],</span> <span class="n">curr_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">Node</span><span class="p">(</span><span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;feature_index&quot;</span><span class="p">],</span> <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;threshold&quot;</span><span class="p">],</span>
                            <span class="n">left_subtree</span><span class="p">,</span> <span class="n">right_subtree</span><span class="p">,</span> <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;info_gain&quot;</span><span class="p">])</span>

        <span class="n">leaf_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_leaf_value</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Node</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">leaf_value</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_best_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
        <span class="n">best_split</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">max_info_gain</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">feature_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
            <span class="n">feature_values</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="n">feature_index</span><span class="p">]</span>
            <span class="n">possible_thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">feature_values</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">possible_thresholds</span><span class="p">:</span>
                <span class="n">dataset_left</span><span class="p">,</span> <span class="n">dataset_right</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">feature_index</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_left</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_right</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">y</span><span class="p">,</span> <span class="n">left_y</span><span class="p">,</span> <span class="n">right_y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dataset_left</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dataset_right</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">curr_info_gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">information_gain</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">left_y</span><span class="p">,</span> <span class="n">right_y</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">curr_info_gain</span> <span class="o">&gt;</span> <span class="n">max_info_gain</span><span class="p">:</span>
                        <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;feature_index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_index</span>
                        <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">threshold</span>
                        <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;dataset_left&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_left</span>
                        <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;dataset_right&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_right</span>
                        <span class="n">best_split</span><span class="p">[</span><span class="s2">&quot;info_gain&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">curr_info_gain</span>
                        <span class="n">max_info_gain</span> <span class="o">=</span> <span class="n">curr_info_gain</span>
        <span class="k">return</span> <span class="n">best_split</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">feature_index</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
        <span class="n">dataset_left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">dataset</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">])</span>
        <span class="n">dataset_right</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">dataset</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">dataset_left</span><span class="p">,</span> <span class="n">dataset_right</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">information_gain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent</span><span class="p">,</span> <span class="n">l_child</span><span class="p">,</span> <span class="n">r_child</span><span class="p">):</span>
        <span class="n">weight_l</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">l_child</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>
        <span class="n">weight_r</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">r_child</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>
        <span class="n">gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gini_impurity</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">weight_l</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gini_impurity</span><span class="p">(</span><span class="n">l_child</span><span class="p">)</span> <span class="o">+</span> <span class="n">weight_r</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gini_impurity</span><span class="p">(</span><span class="n">r_child</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">gain</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">gini_impurity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">gini</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="n">class_labels</span><span class="p">:</span>
            <span class="n">p_cls</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">gini</span> <span class="o">+=</span> <span class="n">p_cls</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">gini</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_leaf_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">count</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_tree</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">make_prediction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">predictions</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">make_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tree</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tree</span><span class="o">.</span><span class="n">value</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span> <span class="k">return</span> <span class="n">tree</span><span class="o">.</span><span class="n">value</span>
        <span class="n">feature_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">tree</span><span class="o">.</span><span class="n">feature_index</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">feature_val</span> <span class="o">&lt;=</span> <span class="n">tree</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_prediction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">left</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_prediction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">right</span><span class="p">)</span>

<span class="c1"># Let&#39;s use it!</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">my_tree</span> <span class="o">=</span> <span class="n">MyDecisionTree</span><span class="p">(</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">my_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">frank</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">frank</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Our REAL hand-built model predicts Frank&#39;s result is:&quot;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div>
<hr />
<h3 id="part-6-lets-discuss">Part 6: Let's Discuss!<a class="headerlink" href="#part-6-lets-discuss" title="Permanent link">&para;</a></h3>
<ol>
<li>What do you think is the biggest advantage of using a library like <code>scikit-learn</code> now that you've seen the complexity behind it?</li>
<li>Our Gini Impurity calculation was simple for our small dataset. How would this process change for a dataset with millions of rows?</li>
<li>Does seeing the "from scratch" version make the <code>scikit-learn</code> code from Lesson 5 make more sense?</li>
</ol>
<hr />
<p><strong>What's Next?</strong></p>
<p>This is the end of our introductory journey, but it's just the beginning of your adventure in AI.</p>
<p>You have learned:</p>
<ul>
<li>
<p>What AI, ML, and DL are.</p>
</li>
<li>
<p>The different ways machines can learn.</p>
</li>
<li>
<p>How to prepare data for a computer.</p>
</li>
<li>
<p>How to build a model with a powerful toolbox.</p>
</li>
<li>
<p>And now, you've even built a real learning algorithm from scratch!</p>
</li>
</ul>
<p>You have a stronger foundation in machine learning than most people on the planet. The next step is to keep building. Keep asking questions. And most importantly, stay curious!</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      SimplestLearn - Making AI and ML Simple
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.expand", "toc.integrate", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
      
    
  </body>
</html>